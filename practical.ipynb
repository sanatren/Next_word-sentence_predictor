{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-23T08:58:47.790384Z",
     "start_time": "2024-12-23T08:58:47.787810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LSTM Training for Next Word Prediction\n",
    "#This notebook implements an LSTM model for next-word prediction using Shakespeare's 'Hamlet' text dataset. The process includes data preparation, model training, and evaluation.\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:59:01.052350Z",
     "start_time": "2024-12-23T08:59:01.048595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ],
   "id": "cfa1c005a6c31eae",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:59:34.041225Z",
     "start_time": "2024-12-23T08:59:34.038826Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #Enable Mixed Precision Training for best gppu utilaization in macOS\n",
    "\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "set_global_policy('mixed_float16')"
   ],
   "id": "c70bc3fd37e0e020",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:59:51.499862Z",
     "start_time": "2024-12-23T08:59:51.495763Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #Download the Gutenberg dataset\n",
    "nltk.download('gutenberg')"
   ],
   "id": "4653824805fdfddf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/sanatankhemariya/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:00:07.574542Z",
     "start_time": "2024-12-23T09:00:07.570117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Shakespeare's Hamlet\n",
    "from nltk.corpus import gutenberg\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')"
   ],
   "id": "dfcbbb9ebf22031d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:00:18.630899Z",
     "start_time": "2024-12-23T09:00:18.627913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('shakespeare.txt', 'w') as file:\n",
    "    file.write(data)\n"
   ],
   "id": "5a39d374599db545",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:00:42.192233Z",
     "start_time": "2024-12-23T09:00:42.174800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Load and Preprocess Text Data\n",
    "\n",
    "# Load the text data\n",
    "with open('shakespeare.txt') as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "# Tokenizing the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(f\"Total Words: {total_words}\")"
   ],
   "id": "6208ff8de923900e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 4818\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Generate Input Sequences\n",
    "\n",
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)\n"
   ],
   "id": "c8b868366dd9073f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:01:38.978418Z",
     "start_time": "2024-12-23T09:01:38.945875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Padding the sequences\n",
    "max_sequence_len = max(len(x) for x in input_sequences)\n",
    "input_seq = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ],
   "id": "78b188f15b94907a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:01:56.638781Z",
     "start_time": "2024-12-23T09:01:56.552470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Splitting predictors (x) and label (y)\n",
    "x, y = input_seq[:, :-1], input_seq[:, -1]\n",
    "y = to_categorical(y, num_classes=total_words)"
   ],
   "id": "c7486403f227e799",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:02:13.303576Z",
     "start_time": "2024-12-23T09:02:13.084932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split into training and testing datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "8e997f7c0493cc4e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:02:27.388230Z",
     "start_time": "2024-12-23T09:02:27.384771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)"
   ],
   "id": "eaf6e6bd2c571c84",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:03:18.776584Z",
     "start_time": "2024-12-23T09:03:18.757342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len - 1))  # Specify input shape\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "#Compile the Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ],
   "id": "7e216a4815c5d1f2",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:51:49.491636Z",
     "start_time": "2024-12-23T08:24:32.805778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,  #Reduce epochs for testing (increase based on needs)\n",
    "    batch_size=32,  #Smaller batch size for memory efficiency\n",
    "    validation_data=(x_test, y_test),\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the Model\n",
    "model.save('shakespeare_lstm_model.h5')\n",
    "\n",
    "# Test GPU Utilization\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "id": "d99cc9953941ab22",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/sanatankhemariya/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 4818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/tf_macos/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2024-12-23 13:54:33.282934: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-12-23 13:54:33.282981: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-12-23 13:54:33.282988: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-12-23 13:54:33.283019: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-23 13:54:33.283035: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ ?                      │   \u001B[38;5;34m0\u001B[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 13:54:34.278580: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 29ms/step - accuracy: 0.0264 - loss: 7.2341 - val_accuracy: 0.0336 - val_loss: 6.7040\n",
      "Epoch 2/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 24ms/step - accuracy: 0.0367 - loss: 6.4801 - val_accuracy: 0.0422 - val_loss: 6.7525\n",
      "Epoch 3/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 24ms/step - accuracy: 0.0421 - loss: 6.3625 - val_accuracy: 0.0484 - val_loss: 6.7563\n",
      "Epoch 4/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 23ms/step - accuracy: 0.0482 - loss: 6.2484 - val_accuracy: 0.0507 - val_loss: 6.7626\n",
      "Epoch 5/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.0533 - loss: 6.0710 - val_accuracy: 0.0560 - val_loss: 6.7566\n",
      "Epoch 6/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.0602 - loss: 5.9305 - val_accuracy: 0.0637 - val_loss: 6.7717\n",
      "Epoch 7/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 28ms/step - accuracy: 0.0729 - loss: 5.8077 - val_accuracy: 0.0647 - val_loss: 6.7736\n",
      "Epoch 8/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.0825 - loss: 5.6530 - val_accuracy: 0.0676 - val_loss: 6.7942\n",
      "Epoch 9/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.0868 - loss: 5.4960 - val_accuracy: 0.0686 - val_loss: 6.8041\n",
      "Epoch 10/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.0902 - loss: 5.3769 - val_accuracy: 0.0723 - val_loss: 6.8915\n",
      "Epoch 11/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 27ms/step - accuracy: 0.0985 - loss: 5.2310 - val_accuracy: 0.0690 - val_loss: 6.9553\n",
      "Epoch 12/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.1053 - loss: 5.0964 - val_accuracy: 0.0670 - val_loss: 7.0244\n",
      "Epoch 13/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.1044 - loss: 4.9834 - val_accuracy: 0.0690 - val_loss: 7.1305\n",
      "Epoch 14/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.1159 - loss: 4.8230 - val_accuracy: 0.0672 - val_loss: 7.1966\n",
      "Epoch 15/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.1178 - loss: 4.7282 - val_accuracy: 0.0647 - val_loss: 7.2813\n",
      "Epoch 16/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.1227 - loss: 4.5928 - val_accuracy: 0.0678 - val_loss: 7.3507\n",
      "Epoch 17/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.1297 - loss: 4.4785 - val_accuracy: 0.0641 - val_loss: 7.4284\n",
      "Epoch 18/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.1391 - loss: 4.3588 - val_accuracy: 0.0635 - val_loss: 7.5019\n",
      "Epoch 19/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.1496 - loss: 4.2535 - val_accuracy: 0.0604 - val_loss: 7.5674\n",
      "Epoch 20/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.1614 - loss: 4.1684 - val_accuracy: 0.0616 - val_loss: 7.6424\n",
      "Epoch 21/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.1750 - loss: 4.0819 - val_accuracy: 0.0614 - val_loss: 7.7009\n",
      "Epoch 22/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.1899 - loss: 3.9541 - val_accuracy: 0.0637 - val_loss: 7.7553\n",
      "Epoch 23/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.2095 - loss: 3.8421 - val_accuracy: 0.0651 - val_loss: 7.8149\n",
      "Epoch 24/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.2228 - loss: 3.7874 - val_accuracy: 0.0583 - val_loss: 7.8677\n",
      "Epoch 25/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 27ms/step - accuracy: 0.2369 - loss: 3.6993 - val_accuracy: 0.0622 - val_loss: 7.9078\n",
      "Epoch 26/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 27ms/step - accuracy: 0.2499 - loss: 3.6381 - val_accuracy: 0.0575 - val_loss: 7.9445\n",
      "Epoch 27/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.2621 - loss: 3.5255 - val_accuracy: 0.0577 - val_loss: 7.9907\n",
      "Epoch 28/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.2793 - loss: 3.4633 - val_accuracy: 0.0561 - val_loss: 8.0350\n",
      "Epoch 29/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.2861 - loss: 3.3976 - val_accuracy: 0.0554 - val_loss: 8.0631\n",
      "Epoch 30/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 29ms/step - accuracy: 0.2964 - loss: 3.3429 - val_accuracy: 0.0556 - val_loss: 8.1146\n",
      "Epoch 31/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.3008 - loss: 3.2899 - val_accuracy: 0.0550 - val_loss: 8.1413\n",
      "Epoch 32/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.3148 - loss: 3.2293 - val_accuracy: 0.0546 - val_loss: 8.1746\n",
      "Epoch 33/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.3193 - loss: 3.1714 - val_accuracy: 0.0593 - val_loss: 8.2006\n",
      "Epoch 34/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.3295 - loss: 3.1174 - val_accuracy: 0.0532 - val_loss: 8.2305\n",
      "Epoch 35/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.3457 - loss: 3.0573 - val_accuracy: 0.0567 - val_loss: 8.2499\n",
      "Epoch 36/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.3544 - loss: 2.9848 - val_accuracy: 0.0560 - val_loss: 8.2833\n",
      "Epoch 37/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.3572 - loss: 2.9947 - val_accuracy: 0.0548 - val_loss: 8.3151\n",
      "Epoch 38/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.3688 - loss: 2.9281 - val_accuracy: 0.0552 - val_loss: 8.3338\n",
      "Epoch 39/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.3683 - loss: 2.8828 - val_accuracy: 0.0554 - val_loss: 8.3697\n",
      "Epoch 40/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.3785 - loss: 2.8433 - val_accuracy: 0.0536 - val_loss: 8.3899\n",
      "Epoch 41/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 26ms/step - accuracy: 0.3928 - loss: 2.7885 - val_accuracy: 0.0540 - val_loss: 8.4291\n",
      "Epoch 42/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.4000 - loss: 2.7449 - val_accuracy: 0.0536 - val_loss: 8.4479\n",
      "Epoch 43/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.4094 - loss: 2.6998 - val_accuracy: 0.0560 - val_loss: 8.4540\n",
      "Epoch 44/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4175 - loss: 2.6803 - val_accuracy: 0.0540 - val_loss: 8.4813\n",
      "Epoch 45/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4206 - loss: 2.6319 - val_accuracy: 0.0530 - val_loss: 8.5168\n",
      "Epoch 46/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4224 - loss: 2.5958 - val_accuracy: 0.0525 - val_loss: 8.5397\n",
      "Epoch 47/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4391 - loss: 2.5585 - val_accuracy: 0.0538 - val_loss: 8.5598\n",
      "Epoch 48/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.4383 - loss: 2.5348 - val_accuracy: 0.0561 - val_loss: 8.5775\n",
      "Epoch 49/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4457 - loss: 2.4841 - val_accuracy: 0.0488 - val_loss: 8.5981\n",
      "Epoch 50/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4541 - loss: 2.4412 - val_accuracy: 0.0538 - val_loss: 8.6096\n",
      "Epoch 51/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4678 - loss: 2.4020 - val_accuracy: 0.0534 - val_loss: 8.6467\n",
      "Epoch 52/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4627 - loss: 2.3984 - val_accuracy: 0.0552 - val_loss: 8.6574\n",
      "Epoch 53/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4699 - loss: 2.3669 - val_accuracy: 0.0548 - val_loss: 8.6750\n",
      "Epoch 54/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4772 - loss: 2.3282 - val_accuracy: 0.0548 - val_loss: 8.7122\n",
      "Epoch 55/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4896 - loss: 2.2740 - val_accuracy: 0.0523 - val_loss: 8.7293\n",
      "Epoch 56/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.4932 - loss: 2.2691 - val_accuracy: 0.0536 - val_loss: 8.7533\n",
      "Epoch 57/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.4939 - loss: 2.2485 - val_accuracy: 0.0528 - val_loss: 8.7738\n",
      "Epoch 58/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.5053 - loss: 2.2011 - val_accuracy: 0.0499 - val_loss: 8.7981\n",
      "Epoch 59/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5107 - loss: 2.1771 - val_accuracy: 0.0490 - val_loss: 8.8215\n",
      "Epoch 60/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 24ms/step - accuracy: 0.5087 - loss: 2.1749 - val_accuracy: 0.0515 - val_loss: 8.8303\n",
      "Epoch 61/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5204 - loss: 2.1203 - val_accuracy: 0.0511 - val_loss: 8.8540\n",
      "Epoch 62/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5186 - loss: 2.1201 - val_accuracy: 0.0523 - val_loss: 8.8668\n",
      "Epoch 63/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5274 - loss: 2.0793 - val_accuracy: 0.0493 - val_loss: 8.8990\n",
      "Epoch 64/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5432 - loss: 2.0200 - val_accuracy: 0.0527 - val_loss: 8.9120\n",
      "Epoch 65/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5429 - loss: 2.0135 - val_accuracy: 0.0517 - val_loss: 8.9212\n",
      "Epoch 66/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5424 - loss: 2.0243 - val_accuracy: 0.0486 - val_loss: 8.9646\n",
      "Epoch 67/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5577 - loss: 1.9578 - val_accuracy: 0.0470 - val_loss: 9.0030\n",
      "Epoch 68/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5520 - loss: 1.9742 - val_accuracy: 0.0495 - val_loss: 9.0083\n",
      "Epoch 69/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5630 - loss: 1.9222 - val_accuracy: 0.0492 - val_loss: 9.0412\n",
      "Epoch 70/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5700 - loss: 1.8930 - val_accuracy: 0.0501 - val_loss: 9.0599\n",
      "Epoch 71/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5717 - loss: 1.8853 - val_accuracy: 0.0488 - val_loss: 9.0763\n",
      "Epoch 72/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5795 - loss: 1.8635 - val_accuracy: 0.0505 - val_loss: 9.1176\n",
      "Epoch 73/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5875 - loss: 1.8213 - val_accuracy: 0.0497 - val_loss: 9.1215\n",
      "Epoch 74/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5797 - loss: 1.8184 - val_accuracy: 0.0501 - val_loss: 9.1324\n",
      "Epoch 75/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5931 - loss: 1.7813 - val_accuracy: 0.0476 - val_loss: 9.1768\n",
      "Epoch 76/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5904 - loss: 1.7800 - val_accuracy: 0.0511 - val_loss: 9.1876\n",
      "Epoch 77/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6035 - loss: 1.7300 - val_accuracy: 0.0503 - val_loss: 9.1992\n",
      "Epoch 78/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.5971 - loss: 1.7493 - val_accuracy: 0.0509 - val_loss: 9.2337\n",
      "Epoch 79/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 26ms/step - accuracy: 0.6125 - loss: 1.6968 - val_accuracy: 0.0507 - val_loss: 9.2444\n",
      "Epoch 80/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6093 - loss: 1.7017 - val_accuracy: 0.0495 - val_loss: 9.2723\n",
      "Epoch 81/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6115 - loss: 1.6790 - val_accuracy: 0.0495 - val_loss: 9.2913\n",
      "Epoch 82/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6161 - loss: 1.6599 - val_accuracy: 0.0515 - val_loss: 9.3085\n",
      "Epoch 83/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6266 - loss: 1.6387 - val_accuracy: 0.0455 - val_loss: 9.3374\n",
      "Epoch 84/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6337 - loss: 1.5931 - val_accuracy: 0.0493 - val_loss: 9.3302\n",
      "Epoch 85/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6400 - loss: 1.5910 - val_accuracy: 0.0474 - val_loss: 9.3654\n",
      "Epoch 86/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6357 - loss: 1.5789 - val_accuracy: 0.0484 - val_loss: 9.3926\n",
      "Epoch 87/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6477 - loss: 1.5485 - val_accuracy: 0.0482 - val_loss: 9.3896\n",
      "Epoch 88/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6386 - loss: 1.5680 - val_accuracy: 0.0478 - val_loss: 9.4296\n",
      "Epoch 89/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6424 - loss: 1.5488 - val_accuracy: 0.0466 - val_loss: 9.4301\n",
      "Epoch 90/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6510 - loss: 1.5248 - val_accuracy: 0.0466 - val_loss: 9.4785\n",
      "Epoch 91/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6536 - loss: 1.4988 - val_accuracy: 0.0451 - val_loss: 9.4931\n",
      "Epoch 92/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6568 - loss: 1.5042 - val_accuracy: 0.0470 - val_loss: 9.4936\n",
      "Epoch 93/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 26ms/step - accuracy: 0.6617 - loss: 1.4711 - val_accuracy: 0.0460 - val_loss: 9.4959\n",
      "Epoch 94/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6581 - loss: 1.4737 - val_accuracy: 0.0453 - val_loss: 9.5161\n",
      "Epoch 95/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 27ms/step - accuracy: 0.6719 - loss: 1.4237 - val_accuracy: 0.0449 - val_loss: 9.5532\n",
      "Epoch 96/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 28ms/step - accuracy: 0.6656 - loss: 1.4242 - val_accuracy: 0.0497 - val_loss: 9.5446\n",
      "Epoch 97/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 26ms/step - accuracy: 0.6713 - loss: 1.4226 - val_accuracy: 0.0478 - val_loss: 9.5783\n",
      "Epoch 98/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6715 - loss: 1.4433 - val_accuracy: 0.0476 - val_loss: 9.5812\n",
      "Epoch 99/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 25ms/step - accuracy: 0.6788 - loss: 1.3908 - val_accuracy: 0.0439 - val_loss: 9.6402\n",
      "Epoch 100/100\n",
      "\u001B[1m644/644\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 26ms/step - accuracy: 0.6789 - loss: 1.3896 - val_accuracy: 0.0462 - val_loss: 9.6336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T10:03:59.184309Z",
     "start_time": "2024-12-23T10:03:58.639828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to predict the next word with session clearing\n",
    "from tensorflow.keras.backend import clear_session\n",
    "def predict_next_word_safe(model, tokenizer, text, max_sequence_len):\n",
    "    clear_session()\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    if len(token_list) >= max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]  # Ensure the sequence length matches max_sequence_len-1\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)[0]\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "# Function to predict the next sequence of words with session clearing\n",
    "def predict_next_words_safe(model, tokenizer, text, max_sequence_len, num_words=6, temperature=0.6):\n",
    "    clear_session()\n",
    "    generated_words = []\n",
    "    current_text = text\n",
    "\n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([current_text])[0]\n",
    "        if len(token_list) >= max_sequence_len:\n",
    "            token_list = token_list[-(max_sequence_len-1):]\n",
    "        padded_sequence = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predictions = model.predict(padded_sequence, verbose=0)[0]\n",
    "        predictions = np.clip(np.log(predictions) / temperature, 1e-8, 1.0)\n",
    "        exp_predictions = np.exp(predictions - np.max(predictions))\n",
    "        probabilities = exp_predictions / np.sum(exp_predictions)\n",
    "        predicted_index = np.random.choice(len(probabilities), p=probabilities)\n",
    "        output_word = None\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        if output_word:\n",
    "            generated_words.append(output_word)\n",
    "            current_text += \" \" + output_word\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return current_text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"shall we open up\"\n",
    "print(f\"Input text: {input_text}\")\n",
    "max_sequence_len = max_sequence_len\n",
    "next_word = predict_next_word_safe(model, tokenizer, input_text, max_sequence_len)\n",
    "print(f\"Next Word Prediction: {next_word}\")\n",
    "\n",
    "# Sentence prediction example\n",
    "input_text = \"in the name of the lord\"\n",
    "result = predict_next_words_safe(model, tokenizer, input_text, max_sequence_len)\n",
    "print(f\"Input text: {input_text}\")\n",
    "print(f\"Prediction: {result}\")\n"
   ],
   "id": "553ad0376c7117be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: shall we open up\n",
      "Next Word Prediction: sorrow\n",
      "Input text: in the name of the lord\n",
      "Prediction: in the name of the lord auoyd drift limed naught beards beckons\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Increase the number of epochs for more accuracy ..\n",
   "id": "32350f13cb0ac1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fdd5667ceb6eabef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T10:04:01.425149Z",
     "start_time": "2024-12-23T10:04:01.418492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "id": "b18bb786350f71c8",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T10:04:03.651920Z",
     "start_time": "2024-12-23T10:04:03.616087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the Model\n",
    "model.save('shakespeare_lstm_model.keras')  # Saves in TensorFlow's SavedModel format\n"
   ],
   "id": "c81f6532c82a1c99",
   "outputs": [],
   "execution_count": 84
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
